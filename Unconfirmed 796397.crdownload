#!/usr/bin/env python
# coding: utf-8

# ### The Sparks Foundation || GRIP JUNE 21
# 
# ###  DataScience and Business Analytics Intern 
# 
# ###  Task-3: Exploratory Data Analysis - Retail (Level-Beginner)
# 
# ###  Author:  Nivetha

# ### ..........................................................Importing the necessary Libraries.................................................................

# In[1]:


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns


# ### ...................................................Reading the SampleSuperstore Dataset..................................................

# In[2]:


Data=pd.read_csv(r'C:\Users\NIVETHA\Downloads\SampleSuperstore(1).csv')


# In[3]:


Data.head(7)         


# In[4]:


Data.info()     


# In[5]:


Data.shape             # checking shape of the whole dataset


# ### ..............................................................Identify the Empty cells.......................................................................

# In[6]:


Data.isnull().sum()   # checking Null values


# #### Here All the columns variable are non-null

# ## .....................................................Cleaning the Data................................................................

# ### Is there any Duplicate Record in this dataset? if yes,then remove the duplicate records

# In[7]:


# checking total no of duplicates
 
Data.duplicated().sum()


# In[8]:


# Checking which 17 records are duplicated

Data[Data.duplicated()]


# In[9]:


# Removing the duplicated record from dataset

Data.drop_duplicates(inplace=True)


# In[10]:


# Again checking total no of duplicates

Data.duplicated().sum()                                                                                                


# In[11]:


# checking shape again after removing 17 duplicated rows

Data.shape


# In[12]:


Data['Country'].nunique()


# #### We should drop the country, postal code columns. Because country,postal codes are of no use. so It will not affect further analysis

# In[13]:


# removing the country,postal code

del Data['Country']
del Data['Postal Code']


# In[14]:


# checking the columns again

Data.columns              


# In[15]:


Data.describe()


# ## ....................................................Data Visualization......................................................

# In[16]:


# compare linear relationship between attributes using correlation coefficient generated using heatmap

sns.heatmap(Data.corr(),cmap='viridis',annot=True)
plt.show()


# In[17]:


# total sales

tot=round(sum(Data['Sales']),2)
print('Total sales',tot)


# In[18]:


# total quantity sold

sold=sum(Data['Quantity'])
print('Total Quantity sold',sold)


# In[19]:


# total profit

pf=round(sum(Data['Profit']),2)
print('Total profit',pf)


# #### Total Sales                      = 2296195.59
# #### Total Quantity Sold        = 37820
# #### Total Profit                      = 286241.42

# In[20]:


sns.pairplot(Data)                                           # pairplot takes only numerical values


# In[21]:


fig,ax=plt.subplots(figsize=(10,6))
ax.scatter(Data['Sales'],Data['Profit'],marker=".")
ax.set_xlabel('Sales')
ax.set_ylabel('Profit')
plt.title('Scatterplot')
plt.show()


# ### Sub-category region wise

# In[22]:


plt.figure(figsize=(20,20))
sns.countplot(x="Sub-Category", hue="Region", data=Data)
plt.title('Sub-Category region wise')
plt.show()


# ### Discount region wise

# In[23]:


plt.figure(figsize=(20,20))
sns.countplot(x="Discount", hue="Region", data=Data)
plt.title('Discount region wise')
plt.show()


# In[24]:


Data.hist(bins=50,figsize=(20,15))                           
plt.show()


# In[25]:


#value counts for ship mode
Data['Ship Mode'].value_counts()


# In[26]:


sns.countplot(x=Data['Ship Mode'])


# In[27]:


Data['Segment'].value_counts()


# In[28]:


sns.countplot(x='Segment',data=Data,palette='rainbow')
plt.title('Segment')


# In[29]:


Data['Category'].value_counts()                                # counts the value of category


# In[30]:


sns.countplot(x='Category',data=Data,palette='tab10')         # category visualization using countplot
plt.title('Category')


# In[31]:


Data['Sub-Category'].value_counts()                         # counts the value of sub-category


# ### Five highest sales displayed here

# In[32]:


s=Data.groupby("State")[["Sales","Profit","Discount"]].sum().sort_values(by='Sales',ascending=False)
s.head(5)


# ### First five highest discount diplayed here

# In[33]:


p=Data.groupby("State")[["Sales","Profit","Discount"]].sum().sort_values(by='Discount',ascending=False)
p.head(5)


# ### Profit vs Discount

# In[34]:


sns.lineplot(x='Discount',y='Profit',data=Data,color='Blue')
plt.title('Profit vs Discount')


# ### Observation:
#      
# #### ✅ Here profit and discount picture shows us clearly, that is "High Discount" ultimately leads to loss
# #### ✅less discount products get good profit comparatively high discount
#         

# ## .......................................................THANK YOU..................................................................
